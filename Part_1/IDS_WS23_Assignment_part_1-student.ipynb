{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hzVGH-sH9qLT"
   },
   "source": [
    "\n",
    "# IDS Assignment Part 1\n",
    "\n",
    "This is the first part of the assignment in IDS 2023/2024.\n",
    "\n",
    "Please use this Jupyter notebook to work on the questions posed in the assignment. When you are done, upload the notebook in Moodle at the designated activity. This is the _only_ file that is required. A separate report is _not_ needed and will not be considered for grading.\n",
    "Provide your commented Python code and answers in the corresponding provided cells. Make sure to answer all questions in a clear and explicit manner and discuss your outputs. _Please do not change the general structure of this notebook_. You can, however, add additional markdown or code cells if necessary. **Please DO NOT CLEAR THE OUTPUT of the notebook you are submitting!** Additionally, please ensure that the code notebook runs if placed in the same folder as all of the provided files, delivering the same outputs as the ones you submit in the notebook. This includes being runnable in the bundled conda environment.\n",
    "\n",
    "*Please make sure to include the names and matriculation numbers of all group members in the slot provided below.* If a name or a student id is missing, the student will not receive any points.\n",
    "\n",
    "Hint 1: While working on the assignment, you will get a better understanding of the dataset. Feel free to generate additional results and visualizations to support your answers. For example, this might be useful regarding data modification, data simplification, or output interpretation. **Ensure that all your claims are supported.**\n",
    "\n",
    "Hint 2: **Plan your time wisely.** A few parts of this assignment may take some time to run. It might be necessary to consider time management when you plan your group work. Also, do not attempt to upload your assignment at the last minute before the deadline. This often does not work, and you will miss the deadline. Late submissions will not be considered.\n",
    "\n",
    "Hint 3: RWTHmoodle allows multiple submissions, with every new submission overwriting the previous one. **Partial submissions are possible and encouraged.** This might be helpful in case of technical issues with RWTHMoodle, which may occur close to the deadline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pEWjL2Fc_FDn"
   },
   "source": [
    "**Student names and matriculation numbers**\n",
    "\n",
    "1.)\n",
    "\n",
    "2.)\n",
    "\n",
    "3.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "**Re-Drive - A platform for selling your used car**\n",
    "\n",
    "**Q1: Preprocessing the data set**\n",
    "\n",
    "**Q2: Exploring the data set**\n",
    "- **(a) Exploration of the target feature**\n",
    "- **(b) Exploration of correlations**\n",
    "    - (i) Correleation with numerical attributes\n",
    "    - (ii) Univariate correlations with categorical attributes\n",
    "    - (iii) Multivariate correlations with categorical attributes\n",
    "\n",
    "**Q3: Predicting prices**\n",
    "- **(a) Baseline**\n",
    "- **(b) Prediction by classification**\n",
    "    - (i) Price binning\n",
    "    - (ii) Data transformation for decision trees\n",
    "    - (iii) Model training\n",
    "    - (iv) Price prediction\n",
    "- **(c) Prediction by clustering**\n",
    "    - (i) Data transformation for clustering\n",
    "    - (ii) Computing the distance matrix\n",
    "    - (iii) Applying DBSCAN\n",
    "    - (iv) Price prediction\n",
    "- **(d) Prediction by regression and with neural networks**\n",
    "    - (i) Feature engineering\n",
    "    - (ii) Feature selection\n",
    "    - (iii) Data transformation for regression and neural networks\n",
    "    - (iv) Model training function\n",
    "    - (v) Linear regression\n",
    "    - (vi) Regression with non-linear kernels\n",
    "    - (vii) Neural networks\n",
    "- **(e) Discussion**\n",
    "\n",
    "\n",
    "**Q4: Predicting time-to-sale**\n",
    "- **(a) Data preparation**\n",
    "    - (i) Target feature creation\n",
    "    - (ii) Sensitivity and specificity\n",
    "    - (iii) Data transformation for classification problem\n",
    "- **(b) Classifiers**\n",
    "    - (i) Model training\n",
    "    - (ii) Evaluation Part 1\n",
    "    - (iii) Evaluation Part 2\n",
    "- **(c) Discussion**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ZOIE0Qw-X01",
    "tags": []
   },
   "source": [
    "# ReDrive - A platform for selling your used car\n",
    "\n",
    "You finally made it! After years of hard study, you finally obtained a degree in data science. Congratulations!\n",
    "\n",
    "Having a passion for automotive technologies, you decided to combine that passion with your profound knowledge in data science. Together with your colleague N., who has a passion for sustainability, you founded **ReDrive** in the beginning of 2023, an online platform where people can sell their used cars.\n",
    "\n",
    "The first months of your joint venture are going very well, and you are making good revenue. It is time now for you to apply your data science expertise to evaluate your business and to look for improvement potential. Your idea on that is to first explore the data, and then to see if you can create useful models for predicting car prices.\n",
    "\n",
    "The dataset *used_cars.csv* contains information about cars that customers have sold or are trying to sell via ReDrive in 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "65lmibiMU2CS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eMVA2-JCgNgS",
    "tags": []
   },
   "source": [
    "# Q1: Preprocessing the data set **[8 points]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FCRcyAOcSaIY"
   },
   "source": [
    "Using the file *used_cars.csv*, create a dataframe. **[1 point]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "id": "oYbUJRviVvhL",
    "outputId": "3b7edb2f-3102-4635-efca-4fa83009d1ad"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tynx9N1jg2Tp"
   },
   "source": [
    "Provide the names of all columns that contain NaN values. **[1 point]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tfcwkqEpWD_A",
    "outputId": "fe769736-c6d2-4a67-edcf-dd70677a6985"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ol8yTNsxmG2i"
   },
   "source": [
    "**Answer:** \n",
    "\n",
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eRs-ikCdmv4N"
   },
   "source": [
    "Display all rows containing NaN values. **[1 point]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 597
    },
    "id": "dsu7S47kgcLp",
    "outputId": "04048e98-451d-4e53-e1c5-8eeca3752449"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q38Dd2CK0z_l"
   },
   "source": [
    "You investigate the NaN values further. You decide to map the NaN values from the clean_title column to \"No\". Also, you map the NaN values of the accident column to \"Unknown\". **[1 point]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l1ARj34GqF-N"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mdHW7XeM1bbj"
   },
   "source": [
    "Finally, you investigate the NaN values of the fuel_type column. To do so, you inspect the unique values of that column. What is your observation? Which general type of engine is accociated with NaN values in the fuel_type column? **[1 point]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ePfc8HHi1qlA",
    "outputId": "fcbb1b73-64db-4bd6-e30a-74a62ffedcc6"
   },
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_J5evPIU26Z2"
   },
   "source": [
    "**Answer:** \n",
    "\n",
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TmkxgzNu3jTU"
   },
   "source": [
    "Based on your former findings, you decide to map the NaN values of the column fuel_type to a value. Choose a suitable value. **[1 point]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jMKjWkDb25P4"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F7LaEYJ_5nWs"
   },
   "source": [
    "You investigate the other values of the fuel_type column. You decide to remove entries that either have *'â€“'* or *'not supported'* as values. **[1 point]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fZwis8Vw57Lo"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "egIxkmDx6Oxu"
   },
   "source": [
    "How many rows does your final dataframe have? Are there any NaN values left in the columns? **[1 point]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SUaiglj36BNF",
    "outputId": "148a754a-332b-4fdf-b0bf-131164a5fc33"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Rhw_sx66cat"
   },
   "source": [
    "**Answer:** \n",
    "\n",
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0oC-cOv97N9U",
    "tags": []
   },
   "source": [
    "# Q2: Exploring the dataset **[14 points]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-b8scnXg6qOc"
   },
   "source": [
    "From now on, use the dataset `used_cars_preprocessed.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"used_cars_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a12magpBtJof"
   },
   "source": [
    "In the following, you want to explore the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) Exploration of the target feature **[4 points]**\n",
    "\n",
    "You are interested in automatically determining the price of a sold car. To do so, you apply your data science knowledge on predictions. You first create a boxplot concerning the price to get an initial impression of the distribution of this attribute. The boxplot should also show the mean. Are there outliers? What can you say about the spread prices? In addition, provide the average price, first and third quartile, and the standard deviation. \n",
    "\n",
    "**[3 points]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 666
    },
    "id": "JllpiawBfkDt",
    "outputId": "661f3c9a-e46c-4629-892f-e3453f1015c4"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k5PQhyaCgqc1"
   },
   "source": [
    "**Answer:** \n",
    "\n",
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zzv30GVyhK7k"
   },
   "source": [
    "To get deeper insight into the price distribution, you decide to create a histogram. Choose an appropriate number of bins to get an informative plot. What do you observe? \n",
    "\n",
    "**[1 point]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "FmFwyExGhKTG",
    "outputId": "46ddf3b2-45fc-47b9-b7f6-c6981c217559"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_8lvd4dnjZTu"
   },
   "source": [
    "**Answer:** \n",
    "\n",
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "je9v751w5OWN"
   },
   "source": [
    "## (b) Exploration of correlations **[10 points]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you want to investigate possible correlations of other variables with the target feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (i) Correleation with numerical attributes\n",
    "\n",
    "To do so, you create a correlation matrix of the numeric values of dataset. Intepret the correlation values you found between price and *model_year*, *milage*, *horsepower*, *litres*, and *cylinders*. \n",
    "\n",
    "**[3 points]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 537
    },
    "id": "1jWJRjv45L7V",
    "outputId": "f1513f81-012e-4a83-cc83-1a0aa2f63fb0"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jL6mmJ7jqBSr"
   },
   "source": [
    "**Answer:**\n",
    "\n",
    "*Your answer here*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eQHLQWWePff4"
   },
   "source": [
    "### (ii) Univariate correlations with categorical attributes\n",
    "\n",
    "In the following, you consider the categorical attributes. You start with *brand*, *fuel_type*, *accident*, and *clean_title*. Create boxplots for these features to capture the relationship with *price*, also showing the mean. What do you observe? Are there feature values for which you can clearly identify a relationship to the price attribute? Also, comment on the outliers and potential distribution inside a value's prices. Be brief in your answers. \n",
    "\n",
    "**[2.5 points]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0n8Ei53l_42v",
    "outputId": "2c852ae7-7ea3-4f11-8573-2a1f28d248e5"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lNc6qrmHPgJ4"
   },
   "source": [
    "**Answer:**\n",
    "\n",
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "leERQIvmIoz2"
   },
   "source": [
    "### (iii) Multivariate correlations with categorical attributes\n",
    "\n",
    "As the current analysis provides limited insight, you want to include a multivariate view using boxplots that also show the mean. Again, you decide on *brand*, *fuel_type*, *accident*, and *clean_title* as features. You create a boxplot for each pair of features. Based on these, provide a conclusion. Each of the following cells focuses on one feature in particular. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "IWX6BC5MPj4m",
    "outputId": "66ff79ed-6875-4c4a-f2a0-e63335b6ea80"
   },
   "outputs": [],
   "source": [
    "# Multivariate analysis for brand\n",
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vgOMgZX-Kpyp"
   },
   "source": [
    "**Answer: **[2 points]****\n",
    "\n",
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 585
    },
    "id": "rCXHAK8rJ7jS",
    "outputId": "22b785b4-ee35-4d7b-a9b1-17dca8194ba6"
   },
   "outputs": [],
   "source": [
    "# Multivariate analysis for fuel_type\n",
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKgQGWOLvNh3"
   },
   "source": [
    "**Answer: **[1.5 points]****\n",
    "\n",
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "id": "AUV-fU3HNsRB",
    "outputId": "f95f213a-da7a-4c6b-d20d-7811f162c33b"
   },
   "outputs": [],
   "source": [
    "# Multivariate analysis for clean_title\n",
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fo9GquJo4zKO"
   },
   "source": [
    "**Answer: [1 point]**\n",
    "\n",
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NbPO6wqYepU0"
   },
   "source": [
    "# Q3: Predicting prices **[62 points]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z3hiJEddcUj0"
   },
   "source": [
    "After a long day at the office, you and N. go to a local bar to catch up with your old friend W. Over a round of cold drinks, you begin to share the great news about your booming business. Being an expert in data analytics himself, W. is also curious to hear your plans to apply your data science knowledge.\n",
    "\n",
    "\"I've been thinking about selling my old Porsche to make room for a new one,\" W. says to you. \"I'm wondering what price to set for the old one. This is the perfect opportunity for you to try out your new predictive models, don't you think?\"\n",
    "\n",
    "You agree! W. writes down the properties of his Porsche (in the following, also referred to as *target car*) on a napkin. You tell W. that you will call him as soon as you can make a confident estimate for the price of his car. The next morning, you immediately start working on predictive models for car prices.\n",
    "If not sated otherwise, you use the entire pre-processed dataset to create each of the models - load the dataset new at the beginning of every partial question a), b),...d) so you don't accidentally use data you have changed for a different kind of model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car = pd.DataFrame([{\n",
    "      \"brand\": \"Porsche\",\n",
    "      \"model\":  \"911 Carrera S\",\n",
    "      \"model_year\": 2015,\n",
    "      \"milage\": 84500.0,\n",
    "      \"fuel_type\": \"Gasoline\",\n",
    "      \"engine\": \"400.0HP 3.8L Flat 6 Cylinder Engine Gasoline Fuel\",\n",
    "      \"transmission\": \"7-Speed A/T\",\n",
    "      \"ext_col\": \"Black\",\n",
    "      \"int_col\": \"Black\",\n",
    "      \"accident\": \"None reported\",\n",
    "      \"clean_title\": \"Yes\",\n",
    "      \"horsepower\": 400.0,\n",
    "      \"litres\": 3.8,\n",
    "      \"cylinders\": 6.0\n",
    "}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y0pvogMLfg-k"
   },
   "source": [
    "## (a) Baseline **[2 points]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o41E2aKmeza7"
   },
   "source": [
    "First, you want to set a baseline to compare against. The baseline should always use the average price of all cars as a recommended price. Use the pre-processed dataset and the `train_test_split` from *sklearn* with arguments `random_state=3` and `test_size=0.05`. To stay consistent, the same split between training and test set should be used throughout the entire assignment.\n",
    "\n",
    "What are the values of the mean absolute error and the root-mean-squared error? \n",
    "\n",
    "**[2 points]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mK0wyDXCevs2",
    "outputId": "93d830a0-ffcf-4c94-bbc2-4bee48ebeba9"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "akMq51r3XDG7"
   },
   "source": [
    "## (b) Prediction by classification **[16 points]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hWPRGo97XFU_"
   },
   "source": [
    "Next, you try to price your car according to similar cars using a decision tree.\n",
    "\n",
    "### (i) Price binning\n",
    "\n",
    "In the following, we want to know the price ranges for selling cars. To use decision trees, you need to discretize prices. We use the following price bins:\n",
    "- [1,800, 10,000]\n",
    "- (10,000, 20,000]\n",
    "- (20,000, 30,000]\n",
    "- (30,000, 40,000]\n",
    "- (40,000, 50,000]\n",
    "- (50,000, 60,000]\n",
    "- (60,000, 80,000]\n",
    "- (80,000, 100,000]\n",
    "- (100,000, 120,000]\n",
    "- (120,000, 140,000]\n",
    "- (140,000, 160,000]\n",
    "- (160,000, 180,000]\n",
    "- (180,000, 220,000]\n",
    "\n",
    "Add the attribute *Price_Bins* to the entire pre-processed data set using the discretization mentioned above for each car. For example, if a car costs 2500, it is put into the bin [1,800, 10,000]. \n",
    "\n",
    "**[1 point]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oRlg_emyZBWy"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kj61FRW_IoYG"
   },
   "source": [
    "You predicted a price range for cars. However, since you cannot enter a price range for selling a car, you have to map each bin to a value. To do so, you use the mean of bins to predict the price. For example, the bin (10,000, 20,000] is mapped to 15,000. Create a dictionary you can use for this mapping. \n",
    "\n",
    "**[1 point]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G6WUeTtr1n_5"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n4rmS7Rqbr05"
   },
   "source": [
    "### (ii) Data transformation for decision trees\n",
    "\n",
    "Using the dataframe extenden by the \"Price_Bins\" column, consider *brand*, *fuel_type*, *model_year*, *accident* and *clean_title* as descriptive features and *Price_Bins* as the target feature. Encode the categorical variables and split your data into a test and training set like before. For the train-test split, use `train_test_split` from *sklearn* with arguments `random_state=3` and `test_size=0.05` again. \n",
    "\n",
    "**[2 points]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6_ci7UaSb-5o",
    "outputId": "6cbb08f2-bb79-46e1-ea03-f5964803fa8e"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BbJD7UusJS1F"
   },
   "source": [
    "### (iii) Model training\n",
    "\n",
    "In the following, you want to use a good deicision tree for predicting prices. To do so,you want to test a set of different values, in particular, max depth of a tree. You test values in [1, 9] (in steps of size one).\n",
    "\n",
    "You use the the algorithm from the *sklearn* library. You set as criterion \"entropy\", `min_samples_leaf=6`, and `random_state=42`.\n",
    "\n",
    "Your goal is to minimize the mean absolute error. Create the prediction using the bins and only apply the dictionary mapping the bins to means to the predicted values before calculating the error. \n",
    "\n",
    "Create a summarizing plot, in which the x-axis represents the maximum tree depth, and the y-axis the mean absolute error as well as the root-mean-square error.\n",
    "\n",
    "**[5 points]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "id": "LPZW8csYZCmq",
    "outputId": "0f4fbcc9-1c90-4692-f462-fba0f062fc20"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn import tree\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bEnfqunOKK8_"
   },
   "source": [
    "Condider your plot, which setting minimizes the mean absolute error and which minimizes the root-mean-square error? Which tree depth would you favorize and what are the error values? Round to the second decimal.  \n",
    "\n",
    "**[2 point]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k16ZIiUyKVgj"
   },
   "source": [
    "**Answer:**\n",
    "\n",
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_7aC9UUPKt6L"
   },
   "source": [
    "Create and plot the tree. What is the first attribute to split on? \n",
    "\n",
    "**[2 points]**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "hpvZIESR_iVC",
    "outputId": "32cc693a-e513-4c61-9e72-1a1c8ae9db37"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0vjo6uGTO5lG"
   },
   "source": [
    "**Answer:** \n",
    "\n",
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84Lnye0Blzdk"
   },
   "source": [
    "What price range does your tree suggest for the following cars:\n",
    "\n",
    "- Porsche, 2004, Gasoline, none accident, and clean title\n",
    "- Mercedes-Benz, 2017, Hybrid, unknown accident, and clean title\n",
    "\n",
    "**[2 points]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ts-i7XQRlz84"
   },
   "source": [
    "**Answer**:\n",
    "\n",
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65wIwK-hozra"
   },
   "source": [
    "### (iv) Price prediction\n",
    "\n",
    "Finally, use the decision tree to predict the price of W.'s car. What is the predicted price? Derive the value from the visualized tree manually (do not use the model's `predict` method). Provide the mean, not the bin.\n",
    "\n",
    "**[1 point]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qvAOxWV9dHjX"
   },
   "source": [
    "**Answer**: \n",
    "\n",
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q04XdSXomKR9",
    "tags": []
   },
   "source": [
    "## (c) Prediction by clustering **[21 points]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import DistanceMetric\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "df = pd.read_csv(\"used_cars_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You come up with another idea to give W. an estimate on his car price. You want to use clustering to find similar cars and use their average price as an estimate.\n",
    "\n",
    "In this task you use DBSCAN to determine clusters of similar cars. For each cluster, you calculate the mean price as a representative. To predict the price for new cars, you assign it to an existing cluster and give the mean price as prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (i) Data transformation for clustering \n",
    "\n",
    "Use *brand*, *milage*, *fuel_type*, *accident*, *clean_title* and *horse_power* as descriptive features and *price* as the target feature. Create a test and training set like before. For the train-test split, use again `train_test_split` from *sklearn* with arguments `random_state=3` and `test_size=0.05`. \n",
    "\n",
    "**[1 point]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (ii) Computing the distance matrix\n",
    "\n",
    "DBSCAN determines clusters based on the distance between different data points. Since some of the features you want to use are not numeric, you have to apply some encoding first to be able to use distance measures. \n",
    "\n",
    "For categorical variables, apply ordinal encoding and compute the Hamming distance; for numerical variables, apply standard scaling and compute the Euclidean distance.\n",
    "\n",
    "For the total distance, first, weight the distance of categorical features by the fraction of categorical variables among the complete feature set. Then, add the distance of numerical features weighted by 1 over the total number of features used.\n",
    "\n",
    "In other words: Let $x=(x_{cat},x_{num})^T$ and $y=(y_{cat},y_{num})^T$ be two samples where $x_{cat}$ and $y_{cat}$ represent their categorical features, and $x_{num}$ and $y_{num}$ represent their numerical features. Let $n_{cat}$ be the number of categorical features and $n_{num}$ be the number of numerical features. Then, the total distance $d_{tot}(x,y)$ between $x$ and $y$ is given by\n",
    "\n",
    "$d_{tot}(x,y)=\\dfrac{n_{cat}\\cdot\\Delta(x_{cat},y_{cat})+d(x_{num},y_{num})}{n_{cat}+n_{num}}$\n",
    "\n",
    "where $\\Delta$ is the Hamming distance and $d$ is the Euclidean distance.\n",
    "\n",
    "Provide a matrix of the computed pairwise total distance between all cars in the training set. Keep the same indexing as in the training set.\n",
    "\n",
    "**[4 points]**\n",
    "\n",
    "*Hint*: Use the preprocessing module of sklearn to prepare your dataset for clustering.\n",
    "\n",
    "*Background*: The Hamming distance is already normed on the number of features used and therefore returns a value between 0 and 1 independent from the number of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: From here on, instead of the distance matrix computed before, use the one provided in `distance.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the new distance matrix\n",
    "dist = np.genfromtxt(\"distance.txt\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (iii) Applying DBSCAN\n",
    "\n",
    "According to a common heuristic, set the minPts parameter of DBSCAN to twice the number of features. Show the according k-distance plot (where *k = minPts - 1*).\n",
    "\n",
    "**[1 point]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have to determine values for the *epsilon* parameter. Based on the previous plot, perform DBSCAN where you vary *epsilon* in the interval (0.0, 0.2] by steps of 0.01.\n",
    "\n",
    "Draw a diagram with the parameter *epsilon* (between 0.01 and 0.2) on the x-axis and the percentage of \n",
    "- clustered samples,\n",
    "- samples in the largest component,\n",
    "- and noise\n",
    "\n",
    "on the y-axis.\n",
    "\n",
    "In a second diagram, plot the number of clusters over *epsilon*.\n",
    "\n",
    "Based on these diagrams, which value for *epsilon* seems to be most suitable? Explain your answer. \n",
    "\n",
    "**[4 points]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: \n",
    "\n",
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: No matter the conclusion made in the previous task, from now on, use the clustering model with *epsilon = 1/6* for predicting the price of W.'s car and evaluating the clustering technique.\n",
    "\n",
    "Apply DBSCAN clustering to your training set based on the provided distance matrix. Answer the following questions:\n",
    "- How many clusters are identified?\n",
    "- What is their average size?\n",
    "- What is the size of the largest cluster (absolute and relative)?\n",
    "- How large is the percentage of unclustered samples (noise)?\n",
    "\n",
    "**[4 points]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (iv) Price prediction\n",
    "\n",
    "Create a dataframe based on the training set where you assign each to each car the label of its corresponding cluster. Then, for each of the obtained clusters, compute their average price as an estimate. \n",
    "\n",
    "**[2 point]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your test set to evaluate your prediction. Therefore, estimate the price of each car in the test set based on an appropriate corresponding cluster. \n",
    "\n",
    "*Hint*: To do that, determine the labels of neighboring cars and assign a label to  each car of the test set as if it were a point still to cluster by DBSCAN. \n",
    "\n",
    "Based on the previously computed average price of each cluster and your function, give a price estimate for each car in the test set.\n",
    "\n",
    "Compare your estimates with the true prices. What are the values of the mean absolute error and the root-mean-square error? \n",
    "\n",
    "**[4 points]**\n",
    "\n",
    "*Note*: The distance matrix between test and training set is provided in `distance_test_to_train.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dist = np.genfromtxt(\"distance_test_to_train.txt\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**:\n",
    "\n",
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, to predict the price for the target car, find a cluster that contains cars with similar features. \n",
    "\n",
    "**Note**: The distance matrix between the target car and the training set is provided in `distance_car_to_train.txt`.\n",
    "\n",
    "Show the cars within a distance of *epsilon* to W's car including all used features, their price and the label of their cluster.\n",
    "\n",
    "Which cluster would you assign the target car to and what is the estimated price? Round to the second decimal. \n",
    "\n",
    "**[1 point]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_dist = np.genfromtxt(\"distance_car_to_train.txt\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: \n",
    "\n",
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k3KKvYXfz3Dv"
   },
   "source": [
    "## (d) Prediction by regression and with neural networks **[17 points]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nnoVwFERFA6Y"
   },
   "source": [
    "In this task, we build regression models and neural networks to predict the car prices.\n",
    "\n",
    "Use the dataset *used_cars_preprocessed.csv* for this subtask as well as the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XqTvpq8zEprj"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"used_cars_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "djXVks5ZAdNm",
    "tags": []
   },
   "source": [
    "### (i) Feature engineering\n",
    "\n",
    "Run the code below that derives a feature *average_model_price* and adds it to the entries in the dataset and to the target car.\n",
    "\n",
    "Do you expect that using this feature as a descriptive feature will be beneficial for the quality of price prediction models? Discuss possible advantages and disadvantages. \n",
    "\n",
    "**[2 points]**\n",
    "\n",
    "*Hint:* You can also first play around with different feature selections in the model training tasks below below to get a feeling for the usefulness of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SStmeNJdBBLm"
   },
   "outputs": [],
   "source": [
    "average_model_prices = {\n",
    "    model: df[df[\"model\"] == model][\"price\"].mean()\n",
    "    for model in set(df[\"model\"].values)\n",
    "}\n",
    "\n",
    "df[\"average_model_price\"] = df.apply(lambda row: average_model_prices[row[\"model\"]], axis = 1)\n",
    "car[\"average_model_price\"] = car.apply(lambda row: average_model_prices[row[\"model\"]], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jEmfq_GxCeMc"
   },
   "source": [
    "**Answer:**\n",
    "\n",
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F47eZRZ9m35y",
    "tags": []
   },
   "source": [
    "### (ii) Feature selection\n",
    "\n",
    "As descriptive features for the models trained in the following, use as categorical feature *accident* and as numerical features *model_year* and *milage*. Depending on your answer for task (i), make a choice whether to include or not to include *average_model_price*.\n",
    "\n",
    "Beside these features, choose one of the three numerical features *horsepower*, *cylinders* and *litres* as another descriptive feature. Motivate your choice with the help of appropriate visualization techniques. \n",
    "\n",
    "**[1 point]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iC4vs-Ui7GkT"
   },
   "source": [
    "**Answer**\n",
    "\n",
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vn8Lsrw_8EiA",
    "tags": []
   },
   "source": [
    "### (iii) Data transformation for regression and neural networks\n",
    "\n",
    "Use *accident*, *model_year* and *milage* as well as your selection from the previous task as descriptive features and *price* as the target feature. Create a test and training set like before, encoding the categorical feature. For the train-test split, use again `train_test_split` from *sklearn* with arguments `random_state=3` and `test_size=0.05`. \n",
    "\n",
    "Normalize the training and test sets as well as the target car. Use the `StandardScaler` from *sklearn* for normalization.\n",
    "\n",
    "*Hint:* Append the target car to the dataset during the encoding procedure.\n",
    "\n",
    "**[2 points]**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CjLRGPHX204q"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ukSdAASa8KzV",
    "tags": []
   },
   "source": [
    "In the following, we will train and evaluate various models for price prediction using the *sklearn* library. To leverage the shared interface for models in the sklearn library, it is convenient to create a function for the model training and evaluation.\n",
    "\n",
    "### (iv) Model training function\n",
    "\n",
    "Implement the body of the function *model_training* below. The function should adhere to the following specification:\n",
    "\n",
    "#### Input:\n",
    "- **model**: A model (e.g., Linear Regression or Neural Network) of the sklearn library.\n",
    "- **x_training_data**: The descriptive data to train the model.\n",
    "- **y_training_data**: The corresponding values of target feature of the training data.\n",
    "- **x_test_data**: The descriptive data to test the model.\n",
    "- **y_test_data**: The corresponding values of target feature of the test data.\n",
    "- **grid_params**: Model parameters for a grid search.\n",
    "\n",
    "#### Output:\n",
    "- **grid**: An object of the class sklearn.model_selection.GridSearchCV that was fitted against the training data. The training should follow a 5-fold cross-validation.\n",
    "- **mean_abs_err**: The mean absolute error of the trained model on the passed test data.\n",
    "- **rms_err**: The root-mean-square error of the trained model on the passed test data.\n",
    "- **best_params**: The optimal parameter configuration, i.e. , the parameters of the best scoring model that was selected by the grid search.\n",
    "\n",
    "**[2 points]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9eK58xtk8NEw",
    "outputId": "5f173e48-5d55-495f-a22c-0c003946991a"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def model_training(model, x_training_data, y_training_data, x_test_data, y_test_data, grid_params):\n",
    "    grid = None\n",
    "    best_params = None\n",
    "    mean_abs_err = None\n",
    "    # # # # # # # # # #\n",
    "    # Your code here  #\n",
    "    # # # # # # # # # #\n",
    "\n",
    "    # # # # # # # # # #\n",
    "    return grid, mean_abs_err, rms_err, best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7NF5-W62Cog",
    "tags": []
   },
   "source": [
    "### (v) Linear regression\n",
    "\n",
    "Apply your function *model_training* to train a linear regressor. Show the errors (MAE, RMSE) and predict the price of the target car. \n",
    "\n",
    "**[1 point]**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Is9bY8vB9D-Y",
    "outputId": "7c0960d8-2b64-4101-cca3-c12d34d25108"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Learning linear relationships only provides limited performance. Therefore, we will analyze non-linear relationships.\n",
    "\n",
    "### (vi) Regression with non-linear kernels\n",
    "\n",
    "Plot the _milage_ feature (x-Axis) in the data against the _price_ feature (y-Axis). \n",
    "\n",
    "Based on the curve, what kernel functions could be used to transform the milage feature? Suggest at least two possible kernel functions. \n",
    "\n",
    "\n",
    "**[2 points]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each kernel function, create a copies of your normalized train sets, test sets and the normalized target car, and extend them with the transformed *milage* feature. Call the _model_training_ function with a linear regression model. Show the errors (MAE, RMSE) and predict the price of the target car. Which of the kernels performs best?\n",
    "\n",
    "**[3 points]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z-cWC9mU2SnY",
    "tags": []
   },
   "source": [
    "### (vii) Neural networks\n",
    "\n",
    "While you are working on your predictive models, N. walks by. With a critical look on your screen, N. says: \"Linear regression is so boring. Nowadays, deep learning is all the rage. Ever heard of ChatGPT and transformer models? Come on, at least you should train a neural network. Watch me, I'll show you,\" N. says, grabs your keyboard and starts typing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pPPp6xehvKtW",
    "outputId": "3e9073f6-d4fd-41a6-9812-43ccdd19a8da"
   },
   "outputs": [],
   "source": [
    "### Provided Code (do not change!)\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "param_grid_nn = {'activation': ['identity'],\n",
    "              \"early_stopping\": [True],\n",
    "              \"validation_fraction\": [0.1],\n",
    "              \"learning_rate\": [\"adaptive\"],\n",
    "              'solver' : ['lbfgs'],\n",
    "              'hidden_layer_sizes': [(2,1), (5,1), (20,1), (100,5)]\n",
    "             }\n",
    "grid_nn, mean_abs_err_nn, rms_err_nn, best_params_nn = model_training(\n",
    "    MLPRegressor(max_iter = 10000), normalized_x_train, y_train, normalized_x_test, y_test, param_grid_nn\n",
    ")\n",
    "print(\"Mean absolute error: {}\".format(mean_abs_err_nn))\n",
    "print(\"Root-mean-square error: {}\".format(rms_err_nn))\n",
    "print(\"Predicted Price of the target car: {}\".format(grid_nn.predict(normalized_car)))\n",
    "print(\"Params of best model: {}\".format(best_params_nn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O2e_R77d-0c_"
   },
   "source": [
    "Execute the code above and interpret the result in comparison to your previous results. In particular, discuss the choice of the activation function and the size of the hidden layers.\n",
    "\n",
    "*Hint:* Set the verbose parameter of the grid search (e.g. , to 3) to get more detailed information on the model training.\n",
    "\n",
    "**[4 points]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## (e) Discussion **[6 points]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarize your findings and discuss limitations of the different prediction approaches. In your discussion, not only refer to the predicted price of the running example and the confidence of your prediction, but also to the methods in general.\n",
    "\n",
    "- Based on the general methodologies, which approach would you prefer and why?\n",
    "- Which approach performed best on the given example?\n",
    "- Are your results consistent with this view?\n",
    "- How would you explain the margin of errors in each approach?\n",
    "- What can you deduce from the differences between MAE and RMSE?\n",
    "- Are there limitations regarding the comparability of the approaches?\n",
    "\n",
    "  \n",
    "**[6 points]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having completed your extensive work on predicting prices, you give W. a call to report your findings. W. is excited to hear about your results, and promises to consider your suggestions. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NrkqMEC4-l2h"
   },
   "source": [
    "# Q4: Predicting time-to-sale **[16 points]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ReDrive** has just rented a small area parking area in front of the facility with unused space for ten cars. Your new project is an exhibition of selected cars on that space. For a one-time commission, sellers can drive up their car there and your company will market the car also locally.\n",
    "\n",
    "To maximize turnover by commissions, your business strategy is to exhibit cars there that are likely to be resold quickly. You decide that the cars on display should have an expected selling time of at most 30 days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SFI1uPQ7hXOV"
   },
   "source": [
    "## (a) Data preparation **[4 points]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, we use the dataset **used_cars_reselling_states.csv**. This is an extension of the working dataframe used so far, also describing when a car has been registered for reselling (*registration_date*), when it was successfully resold (*reselling_date*), and the number of days from registration to reselling (*reselling_time*).\n",
    "\n",
    "Run the code below. The code loads the dataframe, filters out instances without a well-defined outcome for our classification problem, and applies oversampling to the dataframe to circumvent a class imbalance problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5945_DpvI_su"
   },
   "outputs": [],
   "source": [
    "### Provided Code (do not change!)\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"used_cars_reselling_states.csv\")\n",
    "df.dropna(subset=[\"reselling_date\"], inplace=True)\n",
    "\n",
    "# Oversample to circumvent class imbalance \n",
    "df_fast = df[df['reselling_time'] <= 30]\n",
    "df_notfast = df[df['reselling_time'] > 30]\n",
    "sample_size = len(df_notfast) - len(df_fast)\n",
    "random_sample = df_fast.sample(n=sample_size, replace=True)\n",
    "df = pd.concat([df, random_sample], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-WTkmuifjA03"
   },
   "source": [
    "### (i) Target feature creation\n",
    "\n",
    "Use the column *reselling_time* to define a binary categorical (boolean) feature according to the description above and append this feature to the dataframe. \n",
    "\n",
    "**[1 point]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NonESzlohxwh"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ci0lgoEM9yEd",
    "tags": []
   },
   "source": [
    "### (ii) Sensitivity and Specificity\n",
    "\n",
    "You have learned about various quality metrics for classifiers.\n",
    "\n",
    "Briefly illustrate the terms *sensitivity* and *specificity* in the context of the classification problem of fast reselling cars. Suggest which of these metrics is more important for the classifier and provide a justified reason for your suggestion. \n",
    "\n",
    "**[2 points]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KL6Oqyio_Uz7"
   },
   "source": [
    "**Answer:**\n",
    "\n",
    "*Your answer here*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "azxlpRlLh7av"
   },
   "source": [
    "### (iii) Data transformation for classification problem\n",
    "\n",
    "Use *milage*, *model_year* and *price* as descriptive features and your binary feature as the target feature. Create a test and training set like before. For the train-test split, use again `train_test_split` from *sklearn* with arguments `random_state=3` and `test_size=0.05`. \n",
    "\n",
    "Normalize the training and test sets. Use the `StandardScaler` from *sklearn* for normalization.\n",
    "\n",
    "**[1 point]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "OcSxnO0WiAYw",
    "outputId": "5fcd234a-5c2e-44c8-b260-084d1db93505"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "## Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) Classifiers **[10 points]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yeb1KBp-iTao"
   },
   "source": [
    "### (i) Model training\n",
    "\n",
    "Train two classifiers: \n",
    "- A Logistic Regressor,\n",
    "- A Support Vector Machine.\n",
    "\n",
    " **[1 point]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZVXoqbF2iVpX",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (ii) Evaluation, Part 1\n",
    "\n",
    "For both classifiers, show the confusion matrix. \n",
    "\n",
    "**[2 points]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute, if possible, precision, fitness and F1-score of each classifier. Also, compute sensitivity and specificity of each classifier.\n",
    "\n",
    "**[2 points]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Would you choose any of the trained classifiers for application on the described problem? If yes, which one? Justify your answer.\n",
    "\n",
    "**[1 point]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w6HHT0fnivxX"
   },
   "source": [
    "### (iii) Evaluation, Part 2\n",
    "\n",
    "Besides the *predict* method to decide for the class label of an instance, a `LogisticRegression` model from *sklearn* offers the method `predict_proba`. This method takes a list of instances to be classified and returns a list of tuples. Each tuple has two entries: The first entry is the probability for the respective instance to be classified as negative and the second entry is the probability for the instance to be classified as positive. Thus, the entries of each tuple sum up to 1.\n",
    "\n",
    "As you learned in the lecture, we can vary the outcome of a logistic regression classifer by setting a threshold. Instances are labeled as positive if their probability for a positive label is greater than or equal to the threshold.\n",
    "\n",
    "Define the body of the function *threshold_to_rates* below. This function receives a threshold between 0 and 1, and then classifies the test data based on the threshold and the outcome of the instances under the `predict_proba` method of your trained classifier. The function must return a tuple where the first entry is the true positive rate and the second entry is the false positive rate with respect to the given configuration.\n",
    "\n",
    "**Input**:\n",
    "- **h**: A real number within the interval $[0,1]$.\n",
    "\n",
    "**Output**:\n",
    "- **TPR**: The true positive rate of your test data set, based on the given threshold.\n",
    "- **FPR**: The false positive rate of your test data set, based on the given threshold. \n",
    "\n",
    "**[3 points]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 721
    },
    "id": "ZkylqWr0ufcH",
    "outputId": "0001445b-ca1b-4c1a-df67-4748503f8eb1"
   },
   "outputs": [],
   "source": [
    "def threshold_to_rates(h):\n",
    "    tpr = 0\n",
    "    fpr = 0\n",
    "    # # # # # # # # # #\n",
    "    # Your code here  #\n",
    "    # # # # # # # # # #\n",
    "    \n",
    "    # # # # # # # # # #\n",
    "    return (tpr, fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having specified the *threshold_to_rates* function, execute the code box below to plot the ROC curve of your classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given code (Do not change)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "steps =  np.arange(1.0, -0.1, -0.1)\n",
    "steps = [round(h*10)/10 for h in steps]\n",
    "data = {\n",
    "    h : threshold_to_rates(h)\n",
    "    for h in steps\n",
    "}\n",
    "\n",
    "fpr = [data[h][1] for h in steps]\n",
    "tpr = [data[h][0] for h in steps]\n",
    "\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "roc_display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n",
    "                                  estimator_name='Your Logistic Regressor')\n",
    "roc_display.plot()\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--', label='Random Baseline')\n",
    "plt.scatter(fpr, tpr, color='red', marker='o', label='threshold h')\n",
    "for i, label in enumerate(steps):\n",
    "    plt.text(fpr[i], tpr[i], label, fontsize=12, ha='center', va='bottom')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpret the plot. Is there a threshold you would choose for the application of the classifier on the described problem? Justify your answer.\n",
    "\n",
    "**[1 point]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tOCdjKKfFzNv",
    "tags": []
   },
   "source": [
    "## (c) Discussion **[2 points]**\n",
    "\n",
    "Summarize your findings. Discuss limitations and improvement potentials. \n",
    "\n",
    "**[2 points]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FShifzpEGLdf"
   },
   "source": [
    "**Answer:**\n",
    "\n",
    "*Your answer here*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
